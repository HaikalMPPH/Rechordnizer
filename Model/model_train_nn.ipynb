{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a86b41fd-04c1-483c-b2fc-56926d6c3707",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-20 19:55:13.174229: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import joblib\n",
    "import random\n",
    "import gc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd50646b-5ad4-4ade-93b2-0b42201c6398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9bdfa92-78f8-4b7c-b19e-8d2b81782799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cens_C</th>\n",
       "      <th>Cens_Db</th>\n",
       "      <th>Cens_D</th>\n",
       "      <th>Cens_Eb</th>\n",
       "      <th>Cens_E</th>\n",
       "      <th>Cens_F</th>\n",
       "      <th>Cens_Gb</th>\n",
       "      <th>Cens_G</th>\n",
       "      <th>Cens_Ab</th>\n",
       "      <th>Cens_A</th>\n",
       "      <th>Cens_Bb</th>\n",
       "      <th>Cens_B</th>\n",
       "      <th>chord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.458163</td>\n",
       "      <td>0.228498</td>\n",
       "      <td>0.335618</td>\n",
       "      <td>0.385245</td>\n",
       "      <td>0.280831</td>\n",
       "      <td>0.562060</td>\n",
       "      <td>0.101404</td>\n",
       "      <td>0.142517</td>\n",
       "      <td>0.211683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081103</td>\n",
       "      <td>0.007991</td>\n",
       "      <td>FMin7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.456882</td>\n",
       "      <td>0.228481</td>\n",
       "      <td>0.329903</td>\n",
       "      <td>0.386718</td>\n",
       "      <td>0.270461</td>\n",
       "      <td>0.563033</td>\n",
       "      <td>0.104248</td>\n",
       "      <td>0.142325</td>\n",
       "      <td>0.223759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096144</td>\n",
       "      <td>0.008832</td>\n",
       "      <td>FMin7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.454308</td>\n",
       "      <td>0.229081</td>\n",
       "      <td>0.324611</td>\n",
       "      <td>0.388377</td>\n",
       "      <td>0.260669</td>\n",
       "      <td>0.563478</td>\n",
       "      <td>0.107217</td>\n",
       "      <td>0.142526</td>\n",
       "      <td>0.235052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110957</td>\n",
       "      <td>0.009594</td>\n",
       "      <td>FMin7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.450574</td>\n",
       "      <td>0.230340</td>\n",
       "      <td>0.319815</td>\n",
       "      <td>0.390179</td>\n",
       "      <td>0.251621</td>\n",
       "      <td>0.563336</td>\n",
       "      <td>0.110333</td>\n",
       "      <td>0.143008</td>\n",
       "      <td>0.245606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125269</td>\n",
       "      <td>0.010269</td>\n",
       "      <td>FMin7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.445894</td>\n",
       "      <td>0.232287</td>\n",
       "      <td>0.315578</td>\n",
       "      <td>0.392097</td>\n",
       "      <td>0.243367</td>\n",
       "      <td>0.562581</td>\n",
       "      <td>0.113524</td>\n",
       "      <td>0.143594</td>\n",
       "      <td>0.255459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.138864</td>\n",
       "      <td>0.010856</td>\n",
       "      <td>FMin7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.207725</td>\n",
       "      <td>0.076254</td>\n",
       "      <td>0.397630</td>\n",
       "      <td>0.012440</td>\n",
       "      <td>0.081124</td>\n",
       "      <td>0.025550</td>\n",
       "      <td>0.113143</td>\n",
       "      <td>0.602074</td>\n",
       "      <td>0.253705</td>\n",
       "      <td>0.415162</td>\n",
       "      <td>0.012520</td>\n",
       "      <td>0.416366</td>\n",
       "      <td>AMin7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.200846</td>\n",
       "      <td>0.072857</td>\n",
       "      <td>0.392787</td>\n",
       "      <td>0.013882</td>\n",
       "      <td>0.080756</td>\n",
       "      <td>0.028333</td>\n",
       "      <td>0.115661</td>\n",
       "      <td>0.609691</td>\n",
       "      <td>0.257939</td>\n",
       "      <td>0.416193</td>\n",
       "      <td>0.013882</td>\n",
       "      <td>0.409283</td>\n",
       "      <td>AMin7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.194574</td>\n",
       "      <td>0.068975</td>\n",
       "      <td>0.387773</td>\n",
       "      <td>0.015407</td>\n",
       "      <td>0.080133</td>\n",
       "      <td>0.031256</td>\n",
       "      <td>0.117944</td>\n",
       "      <td>0.616832</td>\n",
       "      <td>0.261322</td>\n",
       "      <td>0.417602</td>\n",
       "      <td>0.015407</td>\n",
       "      <td>0.402578</td>\n",
       "      <td>AMin7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.188929</td>\n",
       "      <td>0.064633</td>\n",
       "      <td>0.382609</td>\n",
       "      <td>0.017022</td>\n",
       "      <td>0.079286</td>\n",
       "      <td>0.034334</td>\n",
       "      <td>0.119918</td>\n",
       "      <td>0.623479</td>\n",
       "      <td>0.263771</td>\n",
       "      <td>0.419261</td>\n",
       "      <td>0.017022</td>\n",
       "      <td>0.396526</td>\n",
       "      <td>AMin7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.183925</td>\n",
       "      <td>0.059857</td>\n",
       "      <td>0.377302</td>\n",
       "      <td>0.018739</td>\n",
       "      <td>0.078254</td>\n",
       "      <td>0.037583</td>\n",
       "      <td>0.121490</td>\n",
       "      <td>0.629592</td>\n",
       "      <td>0.265280</td>\n",
       "      <td>0.421086</td>\n",
       "      <td>0.018739</td>\n",
       "      <td>0.391356</td>\n",
       "      <td>AMin7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>399900 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Cens_C   Cens_Db    Cens_D   Cens_Eb    Cens_E    Cens_F   Cens_Gb  \\\n",
       "0    0.458163  0.228498  0.335618  0.385245  0.280831  0.562060  0.101404   \n",
       "1    0.456882  0.228481  0.329903  0.386718  0.270461  0.563033  0.104248   \n",
       "2    0.454308  0.229081  0.324611  0.388377  0.260669  0.563478  0.107217   \n",
       "3    0.450574  0.230340  0.319815  0.390179  0.251621  0.563336  0.110333   \n",
       "4    0.445894  0.232287  0.315578  0.392097  0.243367  0.562581  0.113524   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "108  0.207725  0.076254  0.397630  0.012440  0.081124  0.025550  0.113143   \n",
       "109  0.200846  0.072857  0.392787  0.013882  0.080756  0.028333  0.115661   \n",
       "110  0.194574  0.068975  0.387773  0.015407  0.080133  0.031256  0.117944   \n",
       "111  0.188929  0.064633  0.382609  0.017022  0.079286  0.034334  0.119918   \n",
       "112  0.183925  0.059857  0.377302  0.018739  0.078254  0.037583  0.121490   \n",
       "\n",
       "       Cens_G   Cens_Ab    Cens_A   Cens_Bb    Cens_B  chord  \n",
       "0    0.142517  0.211683  0.000000  0.081103  0.007991  FMin7  \n",
       "1    0.142325  0.223759  0.000000  0.096144  0.008832  FMin7  \n",
       "2    0.142526  0.235052  0.000000  0.110957  0.009594  FMin7  \n",
       "3    0.143008  0.245606  0.000000  0.125269  0.010269  FMin7  \n",
       "4    0.143594  0.255459  0.000000  0.138864  0.010856  FMin7  \n",
       "..        ...       ...       ...       ...       ...    ...  \n",
       "108  0.602074  0.253705  0.415162  0.012520  0.416366  AMin7  \n",
       "109  0.609691  0.257939  0.416193  0.013882  0.409283  AMin7  \n",
       "110  0.616832  0.261322  0.417602  0.015407  0.402578  AMin7  \n",
       "111  0.623479  0.263771  0.419261  0.017022  0.396526  AMin7  \n",
       "112  0.629592  0.265280  0.421086  0.018739  0.391356  AMin7  \n",
       "\n",
       "[399900 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_hdf(\"./dataset.h5\", key=\"df\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "155fb292-42c6-4743-bf2d-4325516940ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chords\n",
      "chord\n",
      "CMin7     15869\n",
      "AbMin7    15750\n",
      "EMin7     15703\n",
      "FMin7     15598\n",
      "GbMin7    15512\n",
      "DMaj7     15464\n",
      "DbMin7    15426\n",
      "GMaj7     15304\n",
      "AMaj7     15211\n",
      "AMin7     15030\n",
      "BMin7     14976\n",
      "BbMin7    14954\n",
      "DMin7     14951\n",
      "EMaj7     14919\n",
      "GMin7     14885\n",
      "AbMaj7    14869\n",
      "BbMaj7    14862\n",
      "EbMin7    14796\n",
      "EbMaj7    14787\n",
      "GbMaj7    14659\n",
      "CMaj7     14659\n",
      "BMaj7     14654\n",
      "DbMaj7    14468\n",
      "FMaj7     14444\n",
      "G7         3414\n",
      "C7         3321\n",
      "Bb7        3311\n",
      "B7         3258\n",
      "Db7        3150\n",
      "Ab7        3148\n",
      "D7         3121\n",
      "Eb7        3111\n",
      "A7         3106\n",
      "Gb7        3081\n",
      "E7         3067\n",
      "F7         3062\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Chords\")\n",
    "print(df[\"chord\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f22910a2-a2b3-4672-8409-0d9335166d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./encoder.xz']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df[\"chord\"]\n",
    "X = df.drop(columns=\"chord\")\n",
    "encoder = sk.preprocessing.LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "joblib.dump(encoder, \"./encoder.xz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01f9d408-e165-4e68-941f-ccdcd4c36b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb64354-b100-49f1-bce9-dc17f43e08b2",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a22ecbda-f306-4fea-9746-7d4ca17726fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X sequence shape:  (399881, 20, 12)\n",
      "y sequence shape:  (399881,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEQUENCE_LEN = 20 # 0.1 * 20.0 = 2 sec of sequence data\n",
    "\n",
    "X_seq, y_encoded_seq = None, None\n",
    "X_seq_list = []\n",
    "y_encoded_seq_list = []\n",
    "for i in range(len(X) - SEQUENCE_LEN + 1):\n",
    "    X_seq_list.append(X.values[i : i + SEQUENCE_LEN, :])\n",
    "    y_encoded_seq_list.append(y_encoded[i + SEQUENCE_LEN - 1])\n",
    "\n",
    "X_seq, y_encoded_seq = np.array(X_seq_list), np.array(y_encoded_seq_list)\n",
    "\n",
    "print(\"X sequence shape: \", X_seq.shape)\n",
    "print(\"y sequence shape: \", y_encoded_seq.shape)\n",
    "\n",
    "del X_seq_list\n",
    "del y_encoded_seq_list\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0d6f7ed-bea8-49ed-a4d1-c8604955e393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X deduplicate shape:  (399881, 20, 12)\n",
      "y deuplicate shape:   (399881,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_seq_flat = X_seq.reshape(X_seq.shape[0], -1)\n",
    "_, unique_idx = np.unique(X_seq_flat, axis=0, return_index=True)\n",
    "unique_idx = np.sort(unique_idx)\n",
    "\n",
    "X_seq = X_seq[unique_idx]\n",
    "y_encoded_seq = y_encoded_seq[unique_idx]\n",
    "\n",
    "print(\"X deduplicate shape: \", X_seq.shape)\n",
    "print(\"y deuplicate shape:  \", y_encoded_seq.shape)\n",
    "\n",
    "del X_seq_flat\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b2ec4ba-ec19-4210-b01d-bbc116eac1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 319904\n",
      "y_train: 319904\n",
      "X_test:  79977\n",
      "y_test:  79977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_seq_train, X_seq_test, y_seq_train, y_seq_test = sk.model_selection.train_test_split(\n",
    "    X_seq,\n",
    "    y_encoded_seq,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_encoded_seq,\n",
    ")\n",
    "\n",
    "print(f\"X_train: {len(X_seq_train)}\")\n",
    "print(f\"y_train: {len(y_seq_train)}\")\n",
    "print(f\"X_test:  {len(X_seq_test)}\")\n",
    "print(f\"y_test:  {len(y_seq_test)}\")\n",
    "\n",
    "del X_seq\n",
    "del y_encoded_seq\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57f6e917-5e8b-49c4-bb6f-97258dfa85e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total feature:  12\n",
      "Total class:    36\n"
     ]
    }
   ],
   "source": [
    "print(\"Total feature: \", X_seq_train.shape[2])\n",
    "print(\"Total class:   \", len(encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bce6e562-b4ae-4bde-bc29-4b1f70ce3550",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = sk.utils.class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_seq_train),\n",
    "    y=y_seq_train,\n",
    ")\n",
    "class_weight_dict = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adb2f230-0a9d-455c-86f4-4fb5ac20590a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.13/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ ?                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ ?                           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_lstm = tf.keras.Sequential([\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True, input_shape=(SEQUENCE_LEN, X_seq_train.shape[2]))),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "        \n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=False)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "    tf.keras.layers.Dense(len(encoder.classes_), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_lstm.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1ea8eb2-821b-4250-a9eb-60978b0f563a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-20 19:55:18.896675: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 245686080 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 26ms/step - accuracy: 0.5416 - loss: 1.6024 - val_accuracy: 0.7015 - val_loss: 1.0026\n",
      "Epoch 2/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 28ms/step - accuracy: 0.7068 - loss: 0.8967 - val_accuracy: 0.7727 - val_loss: 0.7399\n",
      "Epoch 3/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 30ms/step - accuracy: 0.7644 - loss: 0.6657 - val_accuracy: 0.8205 - val_loss: 0.5648\n",
      "Epoch 4/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 33ms/step - accuracy: 0.8085 - loss: 0.5138 - val_accuracy: 0.8544 - val_loss: 0.4544\n",
      "Epoch 5/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 33ms/step - accuracy: 0.8401 - loss: 0.4197 - val_accuracy: 0.8737 - val_loss: 0.3934\n",
      "Epoch 6/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 33ms/step - accuracy: 0.8623 - loss: 0.3589 - val_accuracy: 0.8941 - val_loss: 0.3266\n",
      "Epoch 7/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 33ms/step - accuracy: 0.8773 - loss: 0.3137 - val_accuracy: 0.9018 - val_loss: 0.3064\n",
      "Epoch 8/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 32ms/step - accuracy: 0.8935 - loss: 0.2732 - val_accuracy: 0.9066 - val_loss: 0.2869\n",
      "Epoch 9/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 32ms/step - accuracy: 0.9014 - loss: 0.2551 - val_accuracy: 0.9123 - val_loss: 0.2724\n",
      "Epoch 10/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 35ms/step - accuracy: 0.9103 - loss: 0.2311 - val_accuracy: 0.9196 - val_loss: 0.2505\n",
      "Epoch 11/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 30ms/step - accuracy: 0.9149 - loss: 0.2172 - val_accuracy: 0.9262 - val_loss: 0.2259\n",
      "Epoch 12/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 30ms/step - accuracy: 0.9193 - loss: 0.2065 - val_accuracy: 0.9270 - val_loss: 0.2288\n",
      "Epoch 13/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 30ms/step - accuracy: 0.9241 - loss: 0.1959 - val_accuracy: 0.9325 - val_loss: 0.2125\n",
      "Epoch 14/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 41ms/step - accuracy: 0.9279 - loss: 0.1850 - val_accuracy: 0.9280 - val_loss: 0.2261\n",
      "Epoch 15/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 45ms/step - accuracy: 0.9298 - loss: 0.1832 - val_accuracy: 0.9361 - val_loss: 0.2017\n",
      "Epoch 16/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 39ms/step - accuracy: 0.9342 - loss: 0.1702 - val_accuracy: 0.9347 - val_loss: 0.2029\n",
      "Epoch 17/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 38ms/step - accuracy: 0.9349 - loss: 0.1682 - val_accuracy: 0.9396 - val_loss: 0.1874\n",
      "Epoch 18/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 38ms/step - accuracy: 0.9384 - loss: 0.1592 - val_accuracy: 0.9415 - val_loss: 0.1887\n",
      "Epoch 19/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 35ms/step - accuracy: 0.9402 - loss: 0.1530 - val_accuracy: 0.9403 - val_loss: 0.1907\n",
      "Epoch 20/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 36ms/step - accuracy: 0.9418 - loss: 0.1509 - val_accuracy: 0.9425 - val_loss: 0.1818\n",
      "Epoch 21/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 34ms/step - accuracy: 0.9431 - loss: 0.1447 - val_accuracy: 0.9452 - val_loss: 0.1712\n",
      "Epoch 22/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 34ms/step - accuracy: 0.9455 - loss: 0.1401 - val_accuracy: 0.9444 - val_loss: 0.1763\n",
      "Epoch 23/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 33ms/step - accuracy: 0.9458 - loss: 0.1394 - val_accuracy: 0.9445 - val_loss: 0.1778\n",
      "Epoch 24/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 31ms/step - accuracy: 0.9462 - loss: 0.1405 - val_accuracy: 0.9473 - val_loss: 0.1685\n",
      "Epoch 25/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 31ms/step - accuracy: 0.9483 - loss: 0.1325 - val_accuracy: 0.9457 - val_loss: 0.1693\n",
      "Epoch 26/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 31ms/step - accuracy: 0.9498 - loss: 0.1278 - val_accuracy: 0.9467 - val_loss: 0.1642\n",
      "Epoch 27/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 32ms/step - accuracy: 0.9505 - loss: 0.1275 - val_accuracy: 0.9458 - val_loss: 0.1708\n",
      "Epoch 28/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 32ms/step - accuracy: 0.9527 - loss: 0.1224 - val_accuracy: 0.9495 - val_loss: 0.1598\n",
      "Epoch 29/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 32ms/step - accuracy: 0.9524 - loss: 0.1225 - val_accuracy: 0.9467 - val_loss: 0.1686\n",
      "Epoch 30/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 32ms/step - accuracy: 0.9534 - loss: 0.1204 - val_accuracy: 0.9472 - val_loss: 0.1714\n",
      "Epoch 31/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 32ms/step - accuracy: 0.9547 - loss: 0.1169 - val_accuracy: 0.9490 - val_loss: 0.1591\n",
      "Epoch 32/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 32ms/step - accuracy: 0.9543 - loss: 0.1175 - val_accuracy: 0.9499 - val_loss: 0.1602\n",
      "Epoch 33/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 32ms/step - accuracy: 0.9550 - loss: 0.1145 - val_accuracy: 0.9468 - val_loss: 0.1718\n",
      "Epoch 34/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 32ms/step - accuracy: 0.9561 - loss: 0.1138 - val_accuracy: 0.9492 - val_loss: 0.1640\n",
      "Epoch 35/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 32ms/step - accuracy: 0.9569 - loss: 0.1120 - val_accuracy: 0.9494 - val_loss: 0.1636\n",
      "Epoch 36/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 32ms/step - accuracy: 0.9582 - loss: 0.1090 - val_accuracy: 0.9506 - val_loss: 0.1553\n",
      "Epoch 37/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 32ms/step - accuracy: 0.9580 - loss: 0.1082 - val_accuracy: 0.9504 - val_loss: 0.1563\n",
      "Epoch 38/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 32ms/step - accuracy: 0.9579 - loss: 0.1082 - val_accuracy: 0.9510 - val_loss: 0.1593\n",
      "Epoch 39/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 33ms/step - accuracy: 0.9593 - loss: 0.1046 - val_accuracy: 0.9532 - val_loss: 0.1479\n",
      "Epoch 40/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 33ms/step - accuracy: 0.9592 - loss: 0.1046 - val_accuracy: 0.9533 - val_loss: 0.1428\n",
      "Epoch 41/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 33ms/step - accuracy: 0.9605 - loss: 0.1012 - val_accuracy: 0.9520 - val_loss: 0.1539\n",
      "Epoch 42/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 33ms/step - accuracy: 0.9607 - loss: 0.1010 - val_accuracy: 0.9537 - val_loss: 0.1485\n",
      "Epoch 43/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 33ms/step - accuracy: 0.9622 - loss: 0.0986 - val_accuracy: 0.9521 - val_loss: 0.1529\n",
      "Epoch 44/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 33ms/step - accuracy: 0.9615 - loss: 0.0989 - val_accuracy: 0.9534 - val_loss: 0.1477\n",
      "Epoch 45/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 33ms/step - accuracy: 0.9624 - loss: 0.0943 - val_accuracy: 0.9526 - val_loss: 0.1527\n",
      "Epoch 46/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 33ms/step - accuracy: 0.9622 - loss: 0.0974 - val_accuracy: 0.9526 - val_loss: 0.1549\n",
      "Epoch 47/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 33ms/step - accuracy: 0.9637 - loss: 0.0939 - val_accuracy: 0.9528 - val_loss: 0.1562\n",
      "Epoch 48/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 34ms/step - accuracy: 0.9637 - loss: 0.0937 - val_accuracy: 0.9534 - val_loss: 0.1476\n",
      "Epoch 49/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 34ms/step - accuracy: 0.9640 - loss: 0.0929 - val_accuracy: 0.9548 - val_loss: 0.1409\n",
      "Epoch 50/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 35ms/step - accuracy: 0.9645 - loss: 0.0911 - val_accuracy: 0.9554 - val_loss: 0.1404\n",
      "Epoch 51/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 35ms/step - accuracy: 0.9637 - loss: 0.0927 - val_accuracy: 0.9522 - val_loss: 0.1565\n",
      "Epoch 52/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 36ms/step - accuracy: 0.9642 - loss: 0.0916 - val_accuracy: 0.9550 - val_loss: 0.1458\n",
      "Epoch 53/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 35ms/step - accuracy: 0.9655 - loss: 0.0883 - val_accuracy: 0.9533 - val_loss: 0.1542\n",
      "Epoch 54/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 36ms/step - accuracy: 0.9649 - loss: 0.0905 - val_accuracy: 0.9544 - val_loss: 0.1481\n",
      "Epoch 55/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 36ms/step - accuracy: 0.9657 - loss: 0.0878 - val_accuracy: 0.9551 - val_loss: 0.1414\n",
      "Epoch 56/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 36ms/step - accuracy: 0.9657 - loss: 0.0892 - val_accuracy: 0.9547 - val_loss: 0.1458\n",
      "Epoch 57/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 36ms/step - accuracy: 0.9667 - loss: 0.0848 - val_accuracy: 0.9558 - val_loss: 0.1471\n",
      "Epoch 58/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 36ms/step - accuracy: 0.9659 - loss: 0.0864 - val_accuracy: 0.9535 - val_loss: 0.1504\n",
      "Epoch 59/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 36ms/step - accuracy: 0.9658 - loss: 0.0868 - val_accuracy: 0.9533 - val_loss: 0.1525\n",
      "Epoch 60/500\n",
      "\u001b[1m7998/7998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 36ms/step - accuracy: 0.9664 - loss: 0.0866 - val_accuracy: 0.9543 - val_loss: 0.1513\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "history = model_lstm.fit(\n",
    "    X_seq_train,\n",
    "    y_seq_train,\n",
    "    epochs=500,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping],\n",
    "    class_weight=class_weight_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbe57051-ac8b-497a-b8ef-96279b0662be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - accuracy: 0.9549 - loss: 0.1428\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A7       0.86      0.97      0.91       621\n",
      "       AMaj7       0.96      0.97      0.96      3042\n",
      "       AMin7       0.95      0.97      0.96      3006\n",
      "         Ab7       0.91      0.97      0.94       630\n",
      "      AbMaj7       0.97      0.96      0.96      2974\n",
      "      AbMin7       0.96      0.96      0.96      3150\n",
      "          B7       0.90      0.98      0.94       652\n",
      "       BMaj7       0.97      0.94      0.95      2931\n",
      "       BMin7       0.97      0.94      0.95      2995\n",
      "         Bb7       0.90      0.97      0.94       662\n",
      "      BbMaj7       0.97      0.95      0.96      2972\n",
      "      BbMin7       0.96      0.95      0.95      2991\n",
      "          C7       0.85      0.99      0.91       664\n",
      "       CMaj7       0.96      0.96      0.96      2932\n",
      "       CMin7       0.96      0.95      0.96      3174\n",
      "          D7       0.92      0.97      0.95       624\n",
      "       DMaj7       0.96      0.97      0.96      3093\n",
      "       DMin7       0.96      0.94      0.95      2990\n",
      "         Db7       0.89      0.97      0.93       630\n",
      "      DbMaj7       0.96      0.95      0.95      2894\n",
      "      DbMin7       0.96      0.95      0.96      3085\n",
      "          E7       0.91      0.98      0.94       613\n",
      "       EMaj7       0.96      0.95      0.96      2984\n",
      "       EMin7       0.96      0.95      0.95      3141\n",
      "         Eb7       0.90      0.98      0.94       622\n",
      "      EbMaj7       0.96      0.95      0.96      2957\n",
      "      EbMin7       0.96      0.95      0.95      2959\n",
      "          F7       0.88      0.98      0.93       612\n",
      "       FMaj7       0.95      0.96      0.96      2889\n",
      "       FMin7       0.97      0.93      0.95      3116\n",
      "          G7       0.91      0.97      0.94       683\n",
      "       GMaj7       0.97      0.96      0.97      3061\n",
      "       GMin7       0.96      0.94      0.95      2977\n",
      "         Gb7       0.89      0.97      0.92       616\n",
      "      GbMaj7       0.95      0.96      0.96      2932\n",
      "      GbMin7       0.96      0.95      0.95      3103\n",
      "\n",
      "    accuracy                           0.95     79977\n",
      "   macro avg       0.94      0.96      0.95     79977\n",
      "weighted avg       0.96      0.95      0.95     79977\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_lstm.evaluate(X_seq_test, y_seq_test)\n",
    "y_pred = np.argmax(model_lstm.predict(X_seq_test), axis=1)\n",
    "print(\n",
    "  sk.metrics.classification_report(y_seq_test, y_pred, target_names=encoder.classes_)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ea20c89-c560-42a6-9a76-b8114534bc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm.save(\"model_lstm_128_128.keras\")\n",
    "pd.DataFrame(history.history).to_csv(\"./History/model_lstm_128_128_history.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_venv",
   "language": "python",
   "name": "thesis_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
