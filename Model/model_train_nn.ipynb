{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a86b41fd-04c1-483c-b2fc-56926d6c3707",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 22:28:47.891038: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import joblib\n",
    "import random\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd50646b-5ad4-4ade-93b2-0b42201c6398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9bdfa92-78f8-4b7c-b19e-8d2b81782799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cens_C</th>\n",
       "      <th>Cens_Db</th>\n",
       "      <th>Cens_D</th>\n",
       "      <th>Cens_Eb</th>\n",
       "      <th>Cens_E</th>\n",
       "      <th>Cens_F</th>\n",
       "      <th>Cens_Gb</th>\n",
       "      <th>Cens_G</th>\n",
       "      <th>Cens_Ab</th>\n",
       "      <th>Cens_A</th>\n",
       "      <th>Cens_Bb</th>\n",
       "      <th>Cens_B</th>\n",
       "      <th>chord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.452348</td>\n",
       "      <td>0.229748</td>\n",
       "      <td>0.361109</td>\n",
       "      <td>0.384247</td>\n",
       "      <td>0.289957</td>\n",
       "      <td>0.505736</td>\n",
       "      <td>0.160134</td>\n",
       "      <td>0.192324</td>\n",
       "      <td>0.237007</td>\n",
       "      <td>0.020101</td>\n",
       "      <td>0.073743</td>\n",
       "      <td>0.007858</td>\n",
       "      <td>FMin7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.453124</td>\n",
       "      <td>0.230152</td>\n",
       "      <td>0.356336</td>\n",
       "      <td>0.383752</td>\n",
       "      <td>0.279558</td>\n",
       "      <td>0.509347</td>\n",
       "      <td>0.157981</td>\n",
       "      <td>0.191034</td>\n",
       "      <td>0.246102</td>\n",
       "      <td>0.018734</td>\n",
       "      <td>0.086234</td>\n",
       "      <td>0.008667</td>\n",
       "      <td>FMin7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.452593</td>\n",
       "      <td>0.231150</td>\n",
       "      <td>0.351795</td>\n",
       "      <td>0.383554</td>\n",
       "      <td>0.269870</td>\n",
       "      <td>0.512432</td>\n",
       "      <td>0.156105</td>\n",
       "      <td>0.190244</td>\n",
       "      <td>0.254603</td>\n",
       "      <td>0.017387</td>\n",
       "      <td>0.098308</td>\n",
       "      <td>0.009395</td>\n",
       "      <td>FMin7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.450910</td>\n",
       "      <td>0.232791</td>\n",
       "      <td>0.347583</td>\n",
       "      <td>0.383560</td>\n",
       "      <td>0.260952</td>\n",
       "      <td>0.514989</td>\n",
       "      <td>0.154537</td>\n",
       "      <td>0.189900</td>\n",
       "      <td>0.262471</td>\n",
       "      <td>0.016060</td>\n",
       "      <td>0.109787</td>\n",
       "      <td>0.010040</td>\n",
       "      <td>FMin7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.448296</td>\n",
       "      <td>0.235113</td>\n",
       "      <td>0.343783</td>\n",
       "      <td>0.383615</td>\n",
       "      <td>0.252767</td>\n",
       "      <td>0.517028</td>\n",
       "      <td>0.153299</td>\n",
       "      <td>0.189957</td>\n",
       "      <td>0.269682</td>\n",
       "      <td>0.014843</td>\n",
       "      <td>0.120621</td>\n",
       "      <td>0.010685</td>\n",
       "      <td>FMin7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>0.468113</td>\n",
       "      <td>0.251520</td>\n",
       "      <td>0.445619</td>\n",
       "      <td>0.172908</td>\n",
       "      <td>0.268400</td>\n",
       "      <td>0.162083</td>\n",
       "      <td>0.330289</td>\n",
       "      <td>0.069028</td>\n",
       "      <td>0.260254</td>\n",
       "      <td>0.335813</td>\n",
       "      <td>0.023730</td>\n",
       "      <td>0.309683</td>\n",
       "      <td>D7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>0.455816</td>\n",
       "      <td>0.267095</td>\n",
       "      <td>0.427637</td>\n",
       "      <td>0.185984</td>\n",
       "      <td>0.272747</td>\n",
       "      <td>0.171784</td>\n",
       "      <td>0.333622</td>\n",
       "      <td>0.071528</td>\n",
       "      <td>0.293414</td>\n",
       "      <td>0.321448</td>\n",
       "      <td>0.024044</td>\n",
       "      <td>0.305137</td>\n",
       "      <td>D7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>0.440661</td>\n",
       "      <td>0.282623</td>\n",
       "      <td>0.407051</td>\n",
       "      <td>0.199023</td>\n",
       "      <td>0.276647</td>\n",
       "      <td>0.181347</td>\n",
       "      <td>0.336395</td>\n",
       "      <td>0.074615</td>\n",
       "      <td>0.328778</td>\n",
       "      <td>0.305893</td>\n",
       "      <td>0.024366</td>\n",
       "      <td>0.300389</td>\n",
       "      <td>D7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>0.422635</td>\n",
       "      <td>0.297590</td>\n",
       "      <td>0.384021</td>\n",
       "      <td>0.211749</td>\n",
       "      <td>0.279753</td>\n",
       "      <td>0.190376</td>\n",
       "      <td>0.338419</td>\n",
       "      <td>0.078126</td>\n",
       "      <td>0.365778</td>\n",
       "      <td>0.289019</td>\n",
       "      <td>0.024682</td>\n",
       "      <td>0.295702</td>\n",
       "      <td>D7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>0.401934</td>\n",
       "      <td>0.311681</td>\n",
       "      <td>0.358836</td>\n",
       "      <td>0.223944</td>\n",
       "      <td>0.281803</td>\n",
       "      <td>0.198466</td>\n",
       "      <td>0.339452</td>\n",
       "      <td>0.081948</td>\n",
       "      <td>0.403562</td>\n",
       "      <td>0.270842</td>\n",
       "      <td>0.024975</td>\n",
       "      <td>0.291211</td>\n",
       "      <td>D7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>239900 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Cens_C   Cens_Db    Cens_D   Cens_Eb    Cens_E    Cens_F   Cens_Gb  \\\n",
       "0     0.452348  0.229748  0.361109  0.384247  0.289957  0.505736  0.160134   \n",
       "1     0.453124  0.230152  0.356336  0.383752  0.279558  0.509347  0.157981   \n",
       "2     0.452593  0.231150  0.351795  0.383554  0.269870  0.512432  0.156105   \n",
       "3     0.450910  0.232791  0.347583  0.383560  0.260952  0.514989  0.154537   \n",
       "4     0.448296  0.235113  0.343783  0.383615  0.252767  0.517028  0.153299   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1193  0.468113  0.251520  0.445619  0.172908  0.268400  0.162083  0.330289   \n",
       "1194  0.455816  0.267095  0.427637  0.185984  0.272747  0.171784  0.333622   \n",
       "1195  0.440661  0.282623  0.407051  0.199023  0.276647  0.181347  0.336395   \n",
       "1196  0.422635  0.297590  0.384021  0.211749  0.279753  0.190376  0.338419   \n",
       "1197  0.401934  0.311681  0.358836  0.223944  0.281803  0.198466  0.339452   \n",
       "\n",
       "        Cens_G   Cens_Ab    Cens_A   Cens_Bb    Cens_B  chord  \n",
       "0     0.192324  0.237007  0.020101  0.073743  0.007858  FMin7  \n",
       "1     0.191034  0.246102  0.018734  0.086234  0.008667  FMin7  \n",
       "2     0.190244  0.254603  0.017387  0.098308  0.009395  FMin7  \n",
       "3     0.189900  0.262471  0.016060  0.109787  0.010040  FMin7  \n",
       "4     0.189957  0.269682  0.014843  0.120621  0.010685  FMin7  \n",
       "...        ...       ...       ...       ...       ...    ...  \n",
       "1193  0.069028  0.260254  0.335813  0.023730  0.309683     D7  \n",
       "1194  0.071528  0.293414  0.321448  0.024044  0.305137     D7  \n",
       "1195  0.074615  0.328778  0.305893  0.024366  0.300389     D7  \n",
       "1196  0.078126  0.365778  0.289019  0.024682  0.295702     D7  \n",
       "1197  0.081948  0.403562  0.270842  0.024975  0.291211     D7  \n",
       "\n",
       "[239900 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_hdf(\"./dataset.h5\", key=\"df\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "155fb292-42c6-4743-bf2d-4325516940ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chords\n",
      "chord\n",
      "CMin7     11630\n",
      "AbMin7    11611\n",
      "GbMin7    11600\n",
      "DbMin7    11514\n",
      "FMin7     11264\n",
      "EMin7     11163\n",
      "AMin7     11118\n",
      "DMin7     11039\n",
      "BbMin7    11026\n",
      "EbMin7    10884\n",
      "GMin7     10876\n",
      "BMin7     10825\n",
      "AMaj7      6860\n",
      "EMaj7      6518\n",
      "GbMaj7     6493\n",
      "CMaj7      6406\n",
      "AbMaj7     6379\n",
      "FMaj7      6278\n",
      "BbMaj7     6270\n",
      "GMaj7      6249\n",
      "DbMaj7     6240\n",
      "DMaj7      6212\n",
      "EbMaj7     6185\n",
      "BMaj7      6135\n",
      "G7         2692\n",
      "B7         2536\n",
      "Db7        2428\n",
      "Bb7        2427\n",
      "Ab7        2426\n",
      "C7         2400\n",
      "D7         2399\n",
      "Eb7        2389\n",
      "A7         2384\n",
      "Gb7        2359\n",
      "E7         2345\n",
      "F7         2340\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Chords\")\n",
    "print(df[\"chord\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f22910a2-a2b3-4672-8409-0d9335166d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./encoder.xz']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df[\"chord\"]\n",
    "X = df.drop(columns=\"chord\")\n",
    "encoder = sk.preprocessing.LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "joblib.dump(encoder, \"./encoder.xz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01f9d408-e165-4e68-941f-ccdcd4c36b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb64354-b100-49f1-bce9-dc17f43e08b2",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a22ecbda-f306-4fea-9746-7d4ca17726fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X sequence shape:  (239891, 10, 12)\n",
      "y sequence shape:  (239891,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEQUENCE_LEN = 10 # 0.1 * 20.0 = 2 sec of sequence data\n",
    "\n",
    "X_seq, y_encoded_seq = None, None\n",
    "X_seq_list = []\n",
    "y_encoded_seq_list = []\n",
    "for i in range(len(X) - SEQUENCE_LEN + 1):\n",
    "    X_seq_list.append(X.values[i : i + SEQUENCE_LEN, :])\n",
    "    y_encoded_seq_list.append(y_encoded[i + SEQUENCE_LEN - 1])\n",
    "\n",
    "X_seq, y_encoded_seq = np.array(X_seq_list), np.array(y_encoded_seq_list)\n",
    "\n",
    "print(\"X sequence shape: \", X_seq.shape)\n",
    "print(\"y sequence shape: \", y_encoded_seq.shape)\n",
    "\n",
    "del X_seq_list\n",
    "del y_encoded_seq_list\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0d6f7ed-bea8-49ed-a4d1-c8604955e393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X deduplicate shape:  (239891, 10, 12)\n",
      "y deuplicate shape:   (239891,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_seq_flat = X_seq.reshape(X_seq.shape[0], -1)\n",
    "_, unique_idx = np.unique(X_seq_flat, axis=0, return_index=True)\n",
    "unique_idx = np.sort(unique_idx)\n",
    "\n",
    "X_seq = X_seq[unique_idx]\n",
    "y_encoded_seq = y_encoded_seq[unique_idx]\n",
    "\n",
    "print(\"X deduplicate shape: \", X_seq.shape)\n",
    "print(\"y deuplicate shape:  \", y_encoded_seq.shape)\n",
    "\n",
    "del X_seq_flat\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b2ec4ba-ec19-4210-b01d-bbc116eac1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 191912\n",
      "y_train: 191912\n",
      "X_test:  47979\n",
      "y_test:  47979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_seq_train, X_seq_test, y_seq_train, y_seq_test = sk.model_selection.train_test_split(\n",
    "    X_seq,\n",
    "    y_encoded_seq,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_encoded_seq,\n",
    ")\n",
    "\n",
    "print(f\"X_train: {len(X_seq_train)}\")\n",
    "print(f\"y_train: {len(y_seq_train)}\")\n",
    "print(f\"X_test:  {len(X_seq_test)}\")\n",
    "print(f\"y_test:  {len(y_seq_test)}\")\n",
    "\n",
    "del X_seq\n",
    "del y_encoded_seq\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57f6e917-5e8b-49c4-bb6f-97258dfa85e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total feature:  12\n",
      "Total class:    36\n"
     ]
    }
   ],
   "source": [
    "print(\"Total feature: \", X_seq_train.shape[2])\n",
    "print(\"Total class:   \", len(encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bce6e562-b4ae-4bde-bc29-4b1f70ce3550",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = sk.utils.class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_seq_train),\n",
    "    y=y_seq_train,\n",
    ")\n",
    "class_weight_dict = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adb2f230-0a9d-455c-86f4-4fb5ac20590a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.13/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_lstm = tf.keras.Sequential([\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True, input_shape=(SEQUENCE_LEN, X_seq_train.shape[2]))),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "        \n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=False)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "    tf.keras.layers.Dense(len(encoder.classes_), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_lstm.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1ea8eb2-821b-4250-a9eb-60978b0f563a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 7ms/step - accuracy: 0.4762 - loss: 1.8217 - val_accuracy: 0.6611 - val_loss: 1.1476\n",
      "Epoch 2/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 7ms/step - accuracy: 0.6525 - loss: 1.0965 - val_accuracy: 0.7032 - val_loss: 0.9891\n",
      "Epoch 3/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 7ms/step - accuracy: 0.6974 - loss: 0.9125 - val_accuracy: 0.7410 - val_loss: 0.8480\n",
      "Epoch 4/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 7ms/step - accuracy: 0.7288 - loss: 0.7943 - val_accuracy: 0.7715 - val_loss: 0.7556\n",
      "Epoch 5/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 7ms/step - accuracy: 0.7494 - loss: 0.7149 - val_accuracy: 0.7926 - val_loss: 0.6771\n",
      "Epoch 6/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 7ms/step - accuracy: 0.7726 - loss: 0.6377 - val_accuracy: 0.8014 - val_loss: 0.6413\n",
      "Epoch 7/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.7831 - loss: 0.5988 - val_accuracy: 0.8088 - val_loss: 0.6167\n",
      "Epoch 8/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.7948 - loss: 0.5543 - val_accuracy: 0.8264 - val_loss: 0.5591\n",
      "Epoch 9/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.8063 - loss: 0.5229 - val_accuracy: 0.8371 - val_loss: 0.5353\n",
      "Epoch 10/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.8166 - loss: 0.4940 - val_accuracy: 0.8367 - val_loss: 0.5283\n",
      "Epoch 11/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 8ms/step - accuracy: 0.8237 - loss: 0.4701 - val_accuracy: 0.8472 - val_loss: 0.4936\n",
      "Epoch 12/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 8ms/step - accuracy: 0.8305 - loss: 0.4463 - val_accuracy: 0.8446 - val_loss: 0.5013\n",
      "Epoch 13/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 8ms/step - accuracy: 0.8371 - loss: 0.4304 - val_accuracy: 0.8555 - val_loss: 0.4611\n",
      "Epoch 14/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 8ms/step - accuracy: 0.8430 - loss: 0.4126 - val_accuracy: 0.8686 - val_loss: 0.4287\n",
      "Epoch 15/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.8469 - loss: 0.3992 - val_accuracy: 0.8690 - val_loss: 0.4224\n",
      "Epoch 16/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.8518 - loss: 0.3864 - val_accuracy: 0.8698 - val_loss: 0.4212\n",
      "Epoch 17/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.8556 - loss: 0.3725 - val_accuracy: 0.8746 - val_loss: 0.4131\n",
      "Epoch 18/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.8614 - loss: 0.3604 - val_accuracy: 0.8785 - val_loss: 0.3938\n",
      "Epoch 19/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.8626 - loss: 0.3549 - val_accuracy: 0.8870 - val_loss: 0.3719\n",
      "Epoch 20/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.8687 - loss: 0.3405 - val_accuracy: 0.8830 - val_loss: 0.3745\n",
      "Epoch 21/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.8708 - loss: 0.3329 - val_accuracy: 0.8848 - val_loss: 0.3799\n",
      "Epoch 22/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 8ms/step - accuracy: 0.8727 - loss: 0.3225 - val_accuracy: 0.8893 - val_loss: 0.3646\n",
      "Epoch 23/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 8ms/step - accuracy: 0.8730 - loss: 0.3241 - val_accuracy: 0.8933 - val_loss: 0.3520\n",
      "Epoch 24/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 8ms/step - accuracy: 0.8785 - loss: 0.3113 - val_accuracy: 0.8914 - val_loss: 0.3505\n",
      "Epoch 25/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 8ms/step - accuracy: 0.8801 - loss: 0.3057 - val_accuracy: 0.8891 - val_loss: 0.3618\n",
      "Epoch 26/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.8843 - loss: 0.2989 - val_accuracy: 0.8983 - val_loss: 0.3267\n",
      "Epoch 27/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.8832 - loss: 0.3008 - val_accuracy: 0.8941 - val_loss: 0.3507\n",
      "Epoch 28/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.8864 - loss: 0.2904 - val_accuracy: 0.9015 - val_loss: 0.3233\n",
      "Epoch 29/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.8886 - loss: 0.2848 - val_accuracy: 0.9025 - val_loss: 0.3187\n",
      "Epoch 30/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.8903 - loss: 0.2795 - val_accuracy: 0.9049 - val_loss: 0.3097\n",
      "Epoch 31/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.8896 - loss: 0.2817 - val_accuracy: 0.9070 - val_loss: 0.3016\n",
      "Epoch 32/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.8929 - loss: 0.2726 - val_accuracy: 0.9050 - val_loss: 0.3115\n",
      "Epoch 33/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.8931 - loss: 0.2713 - val_accuracy: 0.9026 - val_loss: 0.3183\n",
      "Epoch 34/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.8973 - loss: 0.2579 - val_accuracy: 0.9078 - val_loss: 0.2978\n",
      "Epoch 35/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.8969 - loss: 0.2603 - val_accuracy: 0.9104 - val_loss: 0.2971\n",
      "Epoch 36/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 8ms/step - accuracy: 0.8998 - loss: 0.2516 - val_accuracy: 0.9106 - val_loss: 0.2909\n",
      "Epoch 37/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.2527 - val_accuracy: 0.9098 - val_loss: 0.2910\n",
      "Epoch 38/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 8ms/step - accuracy: 0.9002 - loss: 0.2512 - val_accuracy: 0.9147 - val_loss: 0.2809\n",
      "Epoch 39/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 8ms/step - accuracy: 0.9020 - loss: 0.2481 - val_accuracy: 0.9133 - val_loss: 0.2867\n",
      "Epoch 40/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 8ms/step - accuracy: 0.9031 - loss: 0.2475 - val_accuracy: 0.9156 - val_loss: 0.2755\n",
      "Epoch 41/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 8ms/step - accuracy: 0.9015 - loss: 0.2475 - val_accuracy: 0.9166 - val_loss: 0.2762\n",
      "Epoch 42/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 8ms/step - accuracy: 0.9050 - loss: 0.2375 - val_accuracy: 0.9149 - val_loss: 0.2764\n",
      "Epoch 43/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 8ms/step - accuracy: 0.9063 - loss: 0.2366 - val_accuracy: 0.9168 - val_loss: 0.2777\n",
      "Epoch 44/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 8ms/step - accuracy: 0.9077 - loss: 0.2331 - val_accuracy: 0.9193 - val_loss: 0.2675\n",
      "Epoch 45/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 8ms/step - accuracy: 0.9083 - loss: 0.2311 - val_accuracy: 0.9137 - val_loss: 0.2889\n",
      "Epoch 46/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 8ms/step - accuracy: 0.9070 - loss: 0.2347 - val_accuracy: 0.9183 - val_loss: 0.2776\n",
      "Epoch 47/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 8ms/step - accuracy: 0.9107 - loss: 0.2241 - val_accuracy: 0.9186 - val_loss: 0.2740\n",
      "Epoch 48/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 8ms/step - accuracy: 0.9087 - loss: 0.2294 - val_accuracy: 0.9189 - val_loss: 0.2706\n",
      "Epoch 49/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 8ms/step - accuracy: 0.9107 - loss: 0.2281 - val_accuracy: 0.9228 - val_loss: 0.2572\n",
      "Epoch 50/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 8ms/step - accuracy: 0.9121 - loss: 0.2207 - val_accuracy: 0.9228 - val_loss: 0.2563\n",
      "Epoch 51/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.9146 - loss: 0.2147 - val_accuracy: 0.9186 - val_loss: 0.2778\n",
      "Epoch 52/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.9128 - loss: 0.2226 - val_accuracy: 0.9214 - val_loss: 0.2596\n",
      "Epoch 53/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.9135 - loss: 0.2158 - val_accuracy: 0.9202 - val_loss: 0.2614\n",
      "Epoch 54/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.9138 - loss: 0.2161 - val_accuracy: 0.9243 - val_loss: 0.2458\n",
      "Epoch 55/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.9143 - loss: 0.2151 - val_accuracy: 0.9245 - val_loss: 0.2502\n",
      "Epoch 56/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.9158 - loss: 0.2112 - val_accuracy: 0.9228 - val_loss: 0.2527\n",
      "Epoch 57/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 8ms/step - accuracy: 0.9168 - loss: 0.2091 - val_accuracy: 0.9234 - val_loss: 0.2479\n",
      "Epoch 58/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 8ms/step - accuracy: 0.9164 - loss: 0.2094 - val_accuracy: 0.9242 - val_loss: 0.2511\n",
      "Epoch 59/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 8ms/step - accuracy: 0.9170 - loss: 0.2081 - val_accuracy: 0.9226 - val_loss: 0.2554\n",
      "Epoch 60/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.9175 - loss: 0.2060 - val_accuracy: 0.9255 - val_loss: 0.2498\n",
      "Epoch 61/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 8ms/step - accuracy: 0.9196 - loss: 0.2012 - val_accuracy: 0.9218 - val_loss: 0.2583\n",
      "Epoch 62/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 8ms/step - accuracy: 0.9197 - loss: 0.2015 - val_accuracy: 0.9246 - val_loss: 0.2553\n",
      "Epoch 63/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 8ms/step - accuracy: 0.9189 - loss: 0.2028 - val_accuracy: 0.9259 - val_loss: 0.2483\n",
      "Epoch 64/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 8ms/step - accuracy: 0.9205 - loss: 0.1985 - val_accuracy: 0.9279 - val_loss: 0.2370\n",
      "Epoch 65/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 8ms/step - accuracy: 0.9218 - loss: 0.1972 - val_accuracy: 0.9234 - val_loss: 0.2595\n",
      "Epoch 66/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 8ms/step - accuracy: 0.9213 - loss: 0.1948 - val_accuracy: 0.9266 - val_loss: 0.2454\n",
      "Epoch 67/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 8ms/step - accuracy: 0.9230 - loss: 0.1946 - val_accuracy: 0.9261 - val_loss: 0.2442\n",
      "Epoch 68/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 8ms/step - accuracy: 0.9249 - loss: 0.1901 - val_accuracy: 0.9276 - val_loss: 0.2407\n",
      "Epoch 69/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 8ms/step - accuracy: 0.9232 - loss: 0.1922 - val_accuracy: 0.9276 - val_loss: 0.2451\n",
      "Epoch 70/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 8ms/step - accuracy: 0.9247 - loss: 0.1896 - val_accuracy: 0.9268 - val_loss: 0.2454\n",
      "Epoch 71/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 8ms/step - accuracy: 0.9262 - loss: 0.1877 - val_accuracy: 0.9257 - val_loss: 0.2480\n",
      "Epoch 72/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 8ms/step - accuracy: 0.9243 - loss: 0.1886 - val_accuracy: 0.9285 - val_loss: 0.2418\n",
      "Epoch 73/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 8ms/step - accuracy: 0.9253 - loss: 0.1882 - val_accuracy: 0.9293 - val_loss: 0.2363\n",
      "Epoch 74/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 8ms/step - accuracy: 0.9244 - loss: 0.1888 - val_accuracy: 0.9282 - val_loss: 0.2441\n",
      "Epoch 75/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.9275 - loss: 0.1826 - val_accuracy: 0.9322 - val_loss: 0.2255\n",
      "Epoch 76/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.9259 - loss: 0.1872 - val_accuracy: 0.9302 - val_loss: 0.2396\n",
      "Epoch 77/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.9268 - loss: 0.1851 - val_accuracy: 0.9291 - val_loss: 0.2451\n",
      "Epoch 78/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.9261 - loss: 0.1888 - val_accuracy: 0.9317 - val_loss: 0.2311\n",
      "Epoch 79/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.1799 - val_accuracy: 0.9334 - val_loss: 0.2299\n",
      "Epoch 80/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.9292 - loss: 0.1808 - val_accuracy: 0.9315 - val_loss: 0.2299\n",
      "Epoch 81/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.9289 - loss: 0.1814 - val_accuracy: 0.9294 - val_loss: 0.2434\n",
      "Epoch 82/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.9272 - loss: 0.1820 - val_accuracy: 0.9325 - val_loss: 0.2302\n",
      "Epoch 83/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.9296 - loss: 0.1797 - val_accuracy: 0.9315 - val_loss: 0.2370\n",
      "Epoch 84/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 8ms/step - accuracy: 0.9275 - loss: 0.1814 - val_accuracy: 0.9318 - val_loss: 0.2317\n",
      "Epoch 85/500\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.9297 - loss: 0.1747 - val_accuracy: 0.9336 - val_loss: 0.2286\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "history = model_lstm.fit(\n",
    "    X_seq_train,\n",
    "    y_seq_train,\n",
    "    epochs=500,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping],\n",
    "    class_weight=class_weight_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbe57051-ac8b-497a-b8ef-96279b0662be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9333 - loss: 0.2216\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A7       0.85      0.97      0.91       477\n",
      "       AMaj7       0.94      0.94      0.94      1372\n",
      "       AMin7       0.94      0.93      0.94      2224\n",
      "         Ab7       0.88      0.98      0.93       485\n",
      "      AbMaj7       0.92      0.95      0.93      1276\n",
      "      AbMin7       0.95      0.91      0.93      2322\n",
      "          B7       0.88      0.94      0.91       507\n",
      "       BMaj7       0.92      0.96      0.94      1227\n",
      "       BMin7       0.94      0.93      0.93      2165\n",
      "         Bb7       0.87      0.97      0.91       485\n",
      "      BbMaj7       0.92      0.95      0.94      1254\n",
      "      BbMin7       0.96      0.90      0.93      2205\n",
      "          C7       0.85      0.97      0.91       480\n",
      "       CMaj7       0.93      0.94      0.94      1281\n",
      "       CMin7       0.96      0.89      0.93      2326\n",
      "          D7       0.87      0.95      0.91       480\n",
      "       DMaj7       0.92      0.95      0.93      1242\n",
      "       DMin7       0.95      0.91      0.93      2208\n",
      "         Db7       0.88      0.98      0.93       485\n",
      "      DbMaj7       0.93      0.96      0.94      1248\n",
      "      DbMin7       0.96      0.90      0.93      2303\n",
      "          E7       0.88      0.94      0.91       469\n",
      "       EMaj7       0.94      0.94      0.94      1304\n",
      "       EMin7       0.95      0.93      0.94      2233\n",
      "         Eb7       0.87      0.96      0.91       478\n",
      "      EbMaj7       0.93      0.96      0.94      1237\n",
      "      EbMin7       0.94      0.93      0.93      2177\n",
      "          F7       0.88      0.96      0.92       468\n",
      "       FMaj7       0.93      0.96      0.94      1256\n",
      "       FMin7       0.96      0.90      0.93      2251\n",
      "          G7       0.84      0.97      0.90       538\n",
      "       GMaj7       0.94      0.95      0.94      1250\n",
      "       GMin7       0.94      0.92      0.93      2175\n",
      "         Gb7       0.83      0.98      0.90       472\n",
      "      GbMaj7       0.94      0.95      0.94      1299\n",
      "      GbMin7       0.95      0.92      0.93      2320\n",
      "\n",
      "    accuracy                           0.93     47979\n",
      "   macro avg       0.91      0.94      0.93     47979\n",
      "weighted avg       0.93      0.93      0.93     47979\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_lstm.evaluate(X_seq_test, y_seq_test)\n",
    "y_pred = np.argmax(model_lstm.predict(X_seq_test), axis=1)\n",
    "print(\n",
    "  sk.metrics.classification_report(y_seq_test, y_pred, target_names=encoder.classes_)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ea20c89-c560-42a6-9a76-b8114534bc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm.save(\"model_lstm_cens_64_64.keras\")\n",
    "pd.DataFrame(history.history).to_csv(\"history_cens_64_64.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a8f23f-b93b-44c3-aeb9-e3d1debe044d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_venv",
   "language": "python",
   "name": "thesis_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
